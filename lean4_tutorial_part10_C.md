# 📘 Lean 4 튜토리얼 — Part 10-C: 베이즈 정리

> **Rosen 이산수학 8판 §7.3 기반 · Mathematics in Lean 참조**
> Part 10-B에서 **조건부확률**(conditional probability)을 배웠다. 이제 그 조건부확률을 "뒤집는" 강력한 도구, **베이즈 정리**(Bayes' theorem)를 만난다.

---

## 🎯 이 파트에서 배울 것

1. **베이즈 정리**(Bayes' theorem)의 직관과 공식
2. 베이즈 정리의 **증명** — 조건부확률의 정의로부터 유도
3. **일반화된 베이즈 정리** — 배반사건의 집합으로 확장
4. **의학 검사 문제** — "양성인데 실제 병에 걸렸을 확률"의 놀라운 결과
5. **베이지안 스팸 필터**(Bayesian spam filter) — 실제 응용
6. Lean 4로 이 모든 것을 **형식화**하는 방법

---

## 10C.0 왜 베이즈 정리가 필요한가?

### 🤔 동기 부여: 일상의 의문

의사가 말한다: "이 검사는 정확도가 99%입니다."

검사 결과가 양성으로 나왔다. 그러면 내가 실제로 병에 걸렸을 확률은 99%일까?

놀랍게도, **아니다!** 병이 매우 희귀하면(예: 10만 명 중 1명), 양성 결과가 나와도 실제 병에 걸렸을 확률은 고작 **0.2%** 정도밖에 안 된다. 이 반직관적인 결과를 정확히 계산해주는 도구가 바로 **베이즈 정리**이다.

### 📜 역사

**토머스 베이즈**(Thomas Bayes, 1702~1761)는 18세기 영국의 장로교 목사이자 수학자였다. 그는 "원인의 확률"을 역으로 추론하는 방법을 연구했고, 이 결과는 그가 죽은 지 3년 후인 1764년에 출판되었다. 이후 프랑스의 위대한 수학자 **라플라스**(Laplace)가 이를 더 발전시켰다.

베이즈 정리는 지난 20년간 **의학**, **법학**, **기계학습**, **공학**, **소프트웨어 개발** 등 다양한 분야에서 일부 정보만 가지고 확률을 추론하기 위해 광범위하게 적용되었다.

---

## 10C.1 베이즈 정리의 기본 아이디어

### 🔑 핵심 질문: "원인 → 결과"를 "결과 → 원인"으로 뒤집기

우리가 이미 알고 있는 것 (Part 10-B에서 배운 **조건부확률**):

- 사건 `F`가 일어날 확률: `p(F)`
- 사건 `F`가 일어났을 때 `E`가 일어날 확률: `p(E | F)`

우리가 알고 싶은 것:

- 사건 `E`가 일어났을 때, 그 **원인**이 `F`였을 확률: `p(F | E)`

이것이 바로 "역방향 추론"이다.

### 비유로 이해하기

| 순방향 (이미 알고 있는 것) | 역방향 (알고 싶은 것) |
|---|---|
| "비가 오면 땅이 젖을 확률" p(젖음 \| 비) | "땅이 젖었는데 비가 왔을 확률" p(비 \| 젖음) |
| "병에 걸리면 검사 양성일 확률" p(양성 \| 병) | "검사 양성인데 실제 병일 확률" p(병 \| 양성) |
| "스팸이면 특정 단어 포함 확률" p(단어 \| 스팸) | "특정 단어가 있으면 스팸일 확률" p(스팸 \| 단어) |

**순방향**은 보통 알기 쉽다 (실험/통계로 구할 수 있다). **역방향**은 직접 구하기 어렵다. 베이즈 정리는 순방향 정보를 이용해 역방향을 계산해준다!

---

## 10C.2 베이즈 정리 — 공식과 증명

### 📐 정리 (베이즈 정리)

> **표본공간**(sample space) `S`에서 사건 `E`와 `F`에 대하여 `p(E) ≠ 0`이고 `p(F) ≠ 0`이면 다음 등식이 성립한다:
>
> ```
>              p(E | F) · p(F)
> p(F | E) = ─────────────────────────────
>            p(E | F) · p(F) + p(E | F̄) · p(F̄)
> ```

여기서 `F̄`는 `F`의 **여사건**(complementary event)이다.

### 🔍 증명 — 차근차근 따라가기

**핵심 도구**: Part 10-B에서 배운 **조건부확률의 정의**

```
p(A | B) = p(A ∩ B) / p(B)    (단, p(B) ≠ 0)
```

**Step 1**: 조건부확률의 정의를 `p(F | E)`에 적용한다.

```
p(F | E) = p(F ∩ E) / p(E)
```

**Step 2**: 마찬가지로 `p(E | F)`의 정의를 정리한다.

```
p(E | F) = p(E ∩ F) / p(F)
```

양변에 `p(F)`를 곱하면:

```
p(E ∩ F) = p(E | F) · p(F)
```

`F ∩ E = E ∩ F`이므로 (교집합의 교환법칙):

```
p(F ∩ E) = p(E | F) · p(F)     ... (*)
```

**Step 3**: 이제 분모 `p(E)`를 계산한다.

사건 `E`는 두 부분으로 나눌 수 있다:
- `E ∩ F`: `E`이면서 `F`인 경우
- `E ∩ F̄`: `E`이면서 `F`가 아닌 경우

`F`와 `F̄`는 **서로 배반**(mutually exclusive)이고, `F ∪ F̄ = S`이므로:

```
E = (E ∩ F) ∪ (E ∩ F̄)
```

`E ∩ F`와 `E ∩ F̄`도 서로 배반이므로:

```
p(E) = p(E ∩ F) + p(E ∩ F̄)
     = p(E | F) · p(F) + p(E | F̄) · p(F̄)     ... (**)
```

**Step 4**: `(*)`를 `(**)`에 대입하면 베이즈 정리를 얻는다.

```
p(F | E) = p(F ∩ E) / p(E)
         = p(E | F) · p(F) / [p(E | F) · p(F) + p(E | F̄) · p(F̄)]
```

증명 완료! ∎

### 🧠 직관적 의미

베이즈 정리의 분자 `p(E | F) · p(F)`는 "`F`가 일어나고 그 결과로 `E`가 일어날 확률"이다. 분모는 "`E`가 일어나는 모든 경로의 확률 합"이다. 따라서 베이즈 정리는 "`E`가 발생한 모든 경우 중에서 `F`가 원인이었던 비율"을 계산한다.

---

## 10C.3 Lean 4로 베이즈 정리 표현하기

확률을 Lean 4에서 다루기 위해 유리수(`ℚ`)를 사용한다. 베이즈 정리를 Lean 4에서 어떻게 형식화하는지 살펴보자.

### 기본 설정

```lean
import Mathlib.Data.Rat.Basic
import Mathlib.Tactic

-- 확률을 유리수로 표현한다
-- p_E_given_F : p(E | F) — "F가 일어났을 때 E가 일어날 확률"
-- p_F         : p(F)     — "F가 일어날 확률"
-- p_Fbar      : p(F̄)    — "F의 여사건이 일어날 확률"

-- 여사건의 확률: p(F̄) = 1 - p(F)
example (p_F : ℚ) (h : p_F = 3/4) : 1 - p_F = 1/4 := by
  subst h; norm_num
```

### 베이즈 정리를 함수로 구현

```lean
/-- 베이즈 정리: p(F|E) 를 계산한다 -/
def bayes (p_E_given_F : ℚ) (p_F : ℚ) (p_E_given_Fbar : ℚ) (p_Fbar : ℚ) : ℚ :=
  (p_E_given_F * p_F) / (p_E_given_F * p_F + p_E_given_Fbar * p_Fbar)

-- 간단한 테스트: 상자 문제 (Rosen 예제 1)
-- 첫 번째 상자: 파란 공 2, 빨간 공 7 → p(빨간|첫째) = 7/9
-- 두 번째 상자: 파란 공 4, 빨간 공 3 → p(빨간|둘째) = 3/7
-- 각 상자를 선택할 확률: p(첫째) = p(둘째) = 1/2
-- 빨간 공이 나왔을 때 첫째 상자였을 확률은?

#eval bayes (7/9) (1/2) (3/7) (1/2)
-- 결과: 49/76 ≈ 0.645
```

### 정리 형태로 증명하기

```lean
/-- 베이즈 정리의 핵심: 분자는 p(E∩F) = p(E|F)·p(F) 이다 -/
theorem bayes_numerator
    (p_E_given_F p_F : ℚ) :
    p_E_given_F * p_F = p_E_given_F * p_F := by
  rfl

/-- 베이즈 정리의 분모: p(E) = p(E|F)·p(F) + p(E|F̄)·p(F̄) -/
theorem bayes_denominator
    (p_E_given_F p_F p_E_given_Fbar p_Fbar : ℚ)
    (hF : p_Fbar = 1 - p_F) :
    p_E_given_F * p_F + p_E_given_Fbar * p_Fbar
    = p_E_given_F * p_F + p_E_given_Fbar * (1 - p_F) := by
  rw [hF]
```

> 💡 **포인트**: Lean 4에서 `rfl`은 "양변이 정의상 같다"는 뜻이다. `rw [hF]`는 가설 `hF`를 이용해 `p_Fbar`를 `1 - p_F`로 **치환**(rewrite)한다. Part 9-I에서 배운 치환(슈퍼포지션)을 여기서 활용하는 것이다!

---

## 10C.4 예제 1: 상자와 공 (Rosen 예제 1)

### 📋 문제

첫 번째 상자에는 파란 공 2개와 빨간 공 7개가, 두 번째 상자에는 파란 공 4개와 빨간 공 3개가 들어 있다. 두 상자 중 하나를 임의로 선택한 다음 그 상자에서 공을 하나 꺼낸다. 만일 빨간 공이 나왔다면 첫 번째 상자를 선택했을 확률은 얼마인가?

### 풀이

- 사건 `E`: 빨간 공을 꺼냄
- 사건 `F`: 첫 번째 상자를 선택함
- `p(E | F) = 7/9` (첫 번째 상자에서 빨간 공 확률)
- `p(E | F̄) = 3/7` (두 번째 상자에서 빨간 공 확률)
- `p(F) = 1/2`, `p(F̄) = 1/2`

베이즈 정리에 대입:

```
p(F | E) = p(E|F)·p(F) / [p(E|F)·p(F) + p(E|F̄)·p(F̄)]
         = (7/9)·(1/2) / [(7/9)·(1/2) + (3/7)·(1/2)]
         = (7/18) / (7/18 + 3/14)
         = (7/18) / (49/126 + 27/126)
         = (7/18) / (76/126)
         = (7/18) / (38/63)
         = (7/18) × (63/38)
         = 49/76
         ≈ 0.645
```

```lean
-- Lean 4로 확인
example : bayes (7/9) (1/2) (3/7) (1/2) = 49/76 := by native_decide

-- 직접 계산으로도 확인
example : (7/9 : ℚ) * (1/2) / ((7/9) * (1/2) + (3/7) * (1/2)) = 49/76 := by
  norm_num
```

> 💡 빨간 공이 나오기 전에는 첫 번째 상자를 선택했을 확률이 1/2(= 0.5)이었다. 그런데 빨간 공이 나왔다는 추가 정보를 얻자, 이 확률이 49/76(≈ 0.645)으로 증가했다! 첫 번째 상자에 빨간 공이 더 많으므로, 빨간 공이 나온 것은 첫 번째 상자였다는 증거가 되는 것이다.

---

## 10C.5 예제 2: 의학 검사의 놀라운 결과 (Rosen 예제 2)

### 📋 문제

100,000명 중 한 명이 걸리는 희귀한 질병이 있고, 매우 정확한 진단 검사가 가능하다고 하자:
- 병에 걸린 사람에 대한 검사 양성 비율: **99%** (true positive)
- 병에 걸리지 않은 사람에 대한 검사 음성 비율: **99.5%** (true negative)

**(a)** 검사 결과가 양성인 사람이 병에 걸렸을 확률은?
**(b)** 검사 결과가 음성인 사람이 병에 걸리지 않았을 확률은?

### 풀이 (a)

- `F` = 병에 걸린 사건, `E` = 검사 결과 양성인 사건
- `p(F) = 1/100000 = 0.00001`
- `p(F̄) = 1 - 0.00001 = 0.99999`
- `p(E | F) = 0.99` (병에 걸렸는데 양성 = **참 양성**(true positive))
- `p(Ē | F) = 0.01` (병에 걸렸는데 음성 = **거짓 음성**(false negative))
- `p(E | F̄) = 0.005` (병에 안 걸렸는데 양성 = **거짓 양성**(false positive))
- `p(Ē | F̄) = 0.995` (병에 안 걸렸는데 음성 = **참 음성**(true negative))

베이즈 정리:

```
p(F | E) = p(E|F)·p(F) / [p(E|F)·p(F) + p(E|F̄)·p(F̄)]
         = (0.99)(0.00001) / [(0.99)(0.00001) + (0.005)(0.99999)]
         = 0.0000099 / [0.0000099 + 0.00499995]
         = 0.0000099 / 0.00500985
         ≈ 0.002
```

```lean
-- Lean 4로 확인 (유리수로 정확히 계산)
-- p(F) = 1/100000, p(E|F) = 99/100, p(E|F̄) = 5/1000 = 1/200

example : bayes (99/100) (1/100000) (1/200) (99999/100000) = 198/100197 := by
  unfold bayes; norm_num

-- 198/100197 ≈ 0.00198 ≈ 0.2%
```

### 😲 놀라운 결과!

검사 정확도가 99%나 되는데, 양성 판정을 받은 사람 중 **실제로 병에 걸린 사람은 겨우 약 0.2%** 밖에 안 된다!

**왜 이런 결과가 나올까?**

핵심은 **병이 너무 희귀**하다는 것이다. 100,000명을 검사한다고 생각해보자:

| 구분 | 인원 | 양성 판정 |
|---|---|---|
| 실제 병에 걸린 사람 | 1명 | 0.99명 (99%가 양성) |
| 병에 안 걸린 사람 | 99,999명 | 약 500명 (0.5%가 거짓 양성) |
| **합계** | 100,000명 | **약 501명** |

양성 판정 501명 중 실제 환자는 겨우 1명이다! 1/501 ≈ 0.2%.

병이 희귀하기 때문에 **거짓 양성**(false positive)의 **절대 수**가 **참 양성**(true positive)보다 훨씬 많다. 이것이 베이즈 정리가 가르쳐주는 핵심 교훈이다.

> ⚠️ 이 결과는 "검사가 무용하다"는 뜻이 **아니다**. 양성 판정을 받으면 추가 검사를 해서 확인해야 한다는 뜻이다. 그리고 양성 판정이 나오지 않은 사람이 병에 걸리지 않았을 확률은 약 **99.99999%** 로 거의 확실하다!

---

## 10C.6 일반화된 베이즈 정리

### 배반 사건이 2개가 아니라 n개인 경우

기본 베이즈 정리에서는 `F`와 `F̄` 두 사건만 있었다. 하지만 원인이 여러 개일 수 있다!

예: "검사 결과가 양성인데, 질병 A 때문인가? 질병 B 때문인가? 질병 C 때문인가?"

### 📐 정리 2 (일반화된 베이즈 정리)

> 사건 `E`가 **표본공간**(sample space) `S`의 사건이고, `F₁, F₂, ..., Fₙ`은 `⋃ᵢFᵢ = S`를 만족하는 서로 **배반사건**(mutually exclusive events)이라고 하자. 모든 `i = 1, 2, ..., n`에 대하여 `p(E) ≠ 0`이고 `p(Fᵢ) ≠ 0`이라 하면:
>
> ```
>              p(E | Fⱼ) · p(Fⱼ)
> p(Fⱼ | E) = ─────────────────────
>              Σᵢ p(E | Fᵢ) · p(Fᵢ)
> ```

이것은 기본 베이즈 정리의 자연스러운 일반화이다. 기본 버전에서 `n = 2`, `F₁ = F`, `F₂ = F̄`로 놓으면 원래 공식을 얻는다.

### Lean 4로 일반화 표현

```lean
/-- 일반화된 베이즈: n개의 배반 원인 사건에 대한 역확률 -/
def bayesGeneral (n : ℕ) (p_E_given : Fin n → ℚ) (p_cause : Fin n → ℚ) (j : Fin n) : ℚ :=
  let numerator := p_E_given j * p_cause j
  let denominator := Finset.sum Finset.univ (fun i => p_E_given i * p_cause i)
  numerator / denominator

-- 예: 3개의 원인, j=0번째 원인의 확률 계산
-- p(E|F₀) = 1/2, p(E|F₁) = 1/3, p(E|F₂) = 1/4
-- p(F₀) = 1/3, p(F₁) = 1/3, p(F₂) = 1/3

#eval bayesGeneral 3 ![1/2, 1/3, 1/4] ![1/3, 1/3, 1/3] 0
-- 결과: (1/2 · 1/3) / (1/2 · 1/3 + 1/3 · 1/3 + 1/4 · 1/3) = (1/6) / (13/36) = 6/13
```

---

## 10C.7 베이지안 스팸 필터

### 📧 실전 응용: 이메일 스팸 판별

**베이지안 스팸 필터**(Bayesian spam filter)는 베이즈 정리를 사용하여 이메일이 스팸인지 아닌지를 판별하는 도구이다.

### 기본 원리

과거에 처리한 메시지에 대한 정보(단어 빈도수 등)를 가지고 새 메시지가 스팸인지 판단한다:

- `S` = 수신된 메시지가 **스팸**(spam)인 사건
- `S̄` = 수신된 메시지가 **스팸이 아닌**(not spam, ham) 사건  
- `E` = 메시지에 단어 `w`가 사용된 사건

특정 단어 `w`에 대해:
- `p(w)` = 스팸 메시지에서 `w`가 사용될 확률 = `nB(w) / |B|`
- `q(w)` = 스팸이 아닌 메시지에서 `w`가 사용될 확률 = `nG(w) / |G|`

여기서 `B`는 스팸으로 분류된 메시지 집합, `G`는 스팸이 아닌 메시지 집합이다.

### 스팸 판정 공식

`p(S) = p(S̄) = 1/2`라고 가정하면(사전 정보가 없을 때):

```
                p(w)
r(w) = ───────────────
        p(w) + q(w)
```

`r(w)`가 스팸 판정 기준(예: 0.9)보다 크다면 해당 메시지를 스팸으로 분류한다.

### Lean 4로 구현

```lean
/-- 단어 w 하나로 스팸 확률 추정 -/
def spamScore (p_w q_w : ℚ) : ℚ :=
  p_w / (p_w + q_w)

-- 예제 3 (Rosen): "Rolex" 단어
-- 스팸 2000개 중 250개에서 사용 → p("Rolex") = 250/2000 = 1/8
-- 스팸 아닌 1000개 중 5개에서 사용 → q("Rolex") = 5/1000 = 1/200

example : spamScore (1/8) (1/200) = 25/26 := by
  unfold spamScore; norm_num

-- 25/26 ≈ 0.962 > 0.9 → 스팸으로 분류!
```

### 여러 단어를 사용한 스팸 필터

단어 하나로는 오류가 크다. 여러 단어를 함께 사용하면 더 정확하다:

```
                  p(w₁) · p(w₂) · ... · p(wₖ)
r(w₁,...,wₖ) = ─────────────────────────────────────────
                p(w₁)·...·p(wₖ) + q(w₁)·...·q(wₖ)
```

```lean
/-- 여러 단어로 스팸 확률 추정 -/
def spamScoreMulti (ps qs : List ℚ) : ℚ :=
  let prod_p := ps.foldl (· * ·) 1
  let prod_q := qs.foldl (· * ·) 1
  prod_p / (prod_p + prod_q)

-- 예제 4 (Rosen): "stock"과 "undervalued" 두 단어
-- p(stock) = 400/2000 = 1/5, q(stock) = 60/1000 = 3/50
-- p(undervalued) = 200/2000 = 1/10, q(undervalued) = 25/1000 = 1/40

#eval spamScoreMulti [1/5, 1/10] [3/50, 1/40]
-- (1/5 · 1/10) / (1/5 · 1/10 + 3/50 · 1/40)
-- = (1/50) / (1/50 + 3/2000) = (1/50) / (43/2000) = 2000/2150 = 40/43 ≈ 0.930
-- 0.930 > 0.9 → 스팸!
```

---

## 10C.8 Lean 4 심화: `calc` 블록으로 단계별 증명

베이즈 정리의 계산 과정을 `calc` 블록으로 보여줄 수 있다. Part 9-I에서 배운 `calc`을 활용하자!

```lean
-- 상자 문제의 계산 과정을 calc으로 표현
example : (7/9 : ℚ) * (1/2) / ((7/9) * (1/2) + (3/7) * (1/2)) = 49/76 := by
  calc (7/9 : ℚ) * (1/2) / ((7/9) * (1/2) + (3/7) * (1/2))
      = (7/18) / (7/18 + 3/14) := by norm_num
    _ = (7/18) / (76/126)     := by norm_num
    _ = 49/76                 := by norm_num
```

### lemma와 theorem의 활용

Part 9-I에서 배운 것처럼, 작은 사실은 `lemma`로, 최종 결과는 `theorem`으로 정리할 수 있다:

```lean
-- 보조정리: 여사건의 확률
lemma complement_prob (p_F : ℚ) (h : 0 ≤ p_F) (h' : p_F ≤ 1) :
    0 ≤ 1 - p_F ∧ 1 - p_F ≤ 1 := by
  constructor <;> linarith

-- 보조정리: 베이즈 분모는 양수 (특정 조건 하에)
lemma bayes_denom_pos
    (pEF pF pEFbar pFbar : ℚ)
    (h1 : 0 < pEF) (h2 : 0 < pF) (h3 : 0 < pEFbar) (h4 : 0 < pFbar) :
    0 < pEF * pF + pEFbar * pFbar := by
  positivity

-- 정리: 베이즈 정리 결과는 0과 1 사이
theorem bayes_bounded
    (pEF pF pEFbar pFbar : ℚ)
    (h1 : 0 < pEF) (h2 : 0 < pF) (h3 : 0 < pEFbar) (h4 : 0 < pFbar)
    (hle1 : pEF ≤ 1) (hle3 : pEFbar ≤ 1) :
    0 ≤ bayes pEF pF pEFbar pFbar := by
  unfold bayes
  apply div_nonneg
  · positivity
  · positivity
```

> 💡 여기서 `lemma`(보조정리)는 작은 벽돌이고, `theorem`(정리)은 그 벽돌들로 쌓은 건물이다. `positivity`는 "양수/비음수" 목표를 자동으로 해결해주는 전술이다.

---

## 10C.9 → (함의)와 ↔ (동치) 복습 — 베이즈 정리에서

Part 9-I에서 배운 `→`와 `↔`를 베이즈 정리 맥락에서 복습하자.

### → (함의, implication): "이면"

```lean
-- "분모가 양수이면 베이즈 결과는 비음수이다"
-- 이것은 →(함의) 관계: A → B (A이면 B이다, 역은 보장 안 됨)
lemma bayes_nonneg_of_denom_pos (num denom : ℚ) (h1 : 0 ≤ num) (h2 : 0 < denom) :
    0 ≤ num / denom := by
  exact div_nonneg h1 (le_of_lt h2)
```

### ↔ (동치, iff): "필요충분조건"

```lean
-- "r(w) > 0.9 ↔ 메시지를 스팸으로 분류한다"
-- 이것은 ↔(동치) 관계: A ↔ B (A이면 B이고, B이면 A이다)
def isSpam (score : ℚ) : Prop := score > 9/10

-- 판정 기준이 0.9일 때, 25/26 > 9/10 ↔ isSpam (25/26)
example : isSpam (25/26) ↔ (25 : ℚ)/26 > 9/10 := by
  unfold isSpam
  constructor
  · intro h; exact h           -- 정방향: →
  · intro h; exact h           -- 역방향: ←
```

> 💡 `→`는 **한 방향**(일방통행): "비가 오면 땅이 젖는다" (역: 땅이 젖으면 비가 온다? 아닐 수도 있다!)
> `↔`는 **양 방향**(양방향): "x > 0 ↔ x는 양수" (둘은 완전히 같은 말)

---

## 10C.10 핵심 전술 정리표

| 전술 | 의미 | 이 파트에서의 사용 |
|---|---|---|
| `norm_num` | 수치 계산을 자동으로 해결 | 유리수 확률 계산 |
| `native_decide` | 결정 가능한 명제를 Lean VM으로 판정 | `#eval` 결과 확인 |
| `unfold` | 정의를 펼침 | `bayes`, `spamScore` 등의 정의를 펼쳐서 증명 |
| `rw [h]` | 가설 `h`를 이용해 치환(대입) | 여사건 확률 치환 |
| `calc` | 단계별 등식 체인 | 베이즈 계산 과정 서술 |
| `positivity` | 양수/비음수 목표 자동 증명 | 분모 > 0 증명 |
| `constructor` | `∧`나 `↔`를 두 부분으로 나눔 | ↔ 증명 시 → 와 ← 나누기 |
| `linarith` | 선형 부등식/등식 자동 해결 | 확률 범위 증명 |
| `subst h` | 등식 가설로 변수를 직접 대체 | `p_F = 3/4` 같은 가설 적용 |

---

## 📝 연습문제 — 설명형 예제

### 연습 1: 기본 베이즈 계산

> 표본공간에서 사건 `E`와 `F`에 대하여 `p(E) = 1/3`, `p(F) = 1/2`, `p(E | F) = 2/5`일 때 `p(F | E)`를 구하라. (Rosen §7.3 연습문제 1)

**풀이 과정**:

먼저 `p(F | E) = p(E ∩ F) / p(E)`이다.

`p(E ∩ F) = p(E | F) · p(F) = (2/5) · (1/2) = 1/5`

따라서 `p(F | E) = (1/5) / (1/3) = 3/5`

```lean
-- 직접 계산
example : (2/5 : ℚ) * (1/2) / (1/3) = 3/5 := by norm_num
```

### 연습 2: 또 다른 기본 문제

> `p(E) = 2/3`, `p(F) = 3/4`, `p(F | E) = 5/8`일 때 `p(E | F)`를 구하라. (Rosen §7.3 연습문제 2)

**풀이**: `p(E ∩ F) = p(F | E) · p(E) = (5/8) · (2/3) = 5/12`

`p(E | F) = p(E ∩ F) / p(F) = (5/12) / (3/4) = 5/9`

```lean
example : (5/8 : ℚ) * (2/3) / (3/4) = 5/9 := by norm_num
```

---

## 📝 연습문제 — 괄호 채우기 (skeleton)

### 연습 3: 상자 문제 변형

> 두 상자 중 하나를 선택. 첫 번째 상자: 흰 공 2, 파란 공 3. 두 번째 상자: 흰 공 4, 파란 공 1. 파란 공을 꺼냈을 때, 첫 번째 상자였을 확률은? (Rosen §7.3 연습문제 3과 유사)

```lean
-- p(파란|첫째) = 3/5, p(파란|둘째) = 1/5
-- p(첫째) = p(둘째) = 1/2

example : bayes (3/5) (1/2) (1/5) (1/2) = (⟨여기를 채우세요⟩) := by
  unfold bayes
  norm_num
```

<details>
<summary>💡 답 보기</summary>

```lean
example : bayes (3/5) (1/2) (1/5) (1/2) = 3/4 := by
  unfold bayes
  norm_num
```

**해설**: 분자 = (3/5)·(1/2) = 3/10, 분모 = 3/10 + (1/5)·(1/2) = 3/10 + 1/10 = 4/10. 따라서 (3/10)/(4/10) = 3/4.

</details>

### 연습 4: 빨간 공 문제

> 두 상자. 첫 번째: 빨간 3, 검은 4. 두 번째: 빨간 5, 검은 6. 빨간 공을 꺼냈을 때 두 번째 상자일 확률은?

```lean
-- p(빨간|첫째) = 3/7, p(빨간|둘째) = 5/11
-- 두 번째 상자일 확률이니 F = 둘째 상자

example : bayes (⟨p(E|F)를 채우세요⟩) (1/2) (⟨p(E|F̄)를 채우세요⟩) (1/2) = 35/68 := by
  unfold bayes; norm_num
```

<details>
<summary>💡 답 보기</summary>

```lean
-- F = 둘째 상자, F̄ = 첫째 상자
-- p(빨간|둘째) = 5/11, p(빨간|첫째) = 3/7
example : bayes (5/11) (1/2) (3/7) (1/2) = 35/68 := by
  unfold bayes; norm_num
```

**해설**: 분자 = (5/11)·(1/2) = 5/22. 분모 = 5/22 + (3/7)·(1/2) = 5/22 + 3/14 = 35/154 + 33/154 = 68/154. 결과 = (5/22)/(68/154) = (5/22)·(154/68) = 770/1496 = 35/68.

</details>

### 연습 5: 의학 검사 변형

> 10,000명 중 한 명이 걸리는 희귀한 유전병. 검사 정확도: 병에 걸린 환자의 99.9%가 양성, 병에 걸리지 않은 환자의 0.2%가 양성. 검사가 양성인 사람이 유전병에 걸렸을 확률은? (Rosen §7.3 연습문제 8과 유사)

```lean
-- p(F) = 1/10000, p(F̄) = 9999/10000
-- p(E|F) = 999/1000, p(E|F̄) = 2/1000 = 1/500

example : bayes (999/1000) (1/10000) (1/500) (9999/10000) = (⟨여기를 채우세요⟩) := by
  unfold bayes; norm_num
```

<details>
<summary>💡 답 보기</summary>

```lean
example : bayes (999/1000) (1/10000) (1/500) (9999/10000) = 999/20997 := by
  unfold bayes; norm_num

-- 999/20997 ≈ 0.0476 ≈ 약 4.8%
-- 검사 양성이어도 실제 병일 확률은 약 4.8%에 불과!
```

</details>

### 연습 6: 스테로이드 검사 (Rosen §7.3 연습문제 5)

> 모든 자전거 선수의 8%가 스테로이드를 복용하고 있다. 검사에서 스테로이드를 복용한 사람이 양성일 비율이 96%이고, 복용하지 않은 사람이 양성일 비율이 9%이다. 스테로이드 검사 결과가 양성인 선수가 실제 스테로이드를 복용했을 확률은?

```lean
-- p(F) = 8/100, p(F̄) = 92/100
-- p(E|F) = 96/100, p(E|F̄) = 9/100

example : bayes (96/100) (8/100) (9/100) (92/100) = (⟨여기를 채우세요⟩) := by
  unfold bayes; norm_num
```

<details>
<summary>💡 답 보기</summary>

```lean
example : bayes (96/100) (8/100) (9/100) (92/100) = 192/399 := by
  unfold bayes; norm_num

-- 192/399 ≈ 0.481 ≈ 약 48.1%
-- 양성이어도 실제 복용했을 확률은 약 48%
```

</details>

### 연습 7: 스팸 필터 기본

> "Rolex"란 단어가 스팸 2000개 중 250개에서, 스팸이 아닌 1000개 중 5개에서 사용되었다. 스팸 판정 기준이 0.9일 때, "Rolex"가 포함된 메시지를 스팸으로 거부해야 하는가? (Rosen 예제 3)

```lean
-- p(Rolex) = 250/2000 = 1/8, q(Rolex) = 5/1000 = 1/200
-- r(Rolex) = p / (p + q)

example : spamScore (⟨p를 채우세요⟩) (⟨q를 채우세요⟩) = 25/26 := by
  unfold spamScore; norm_num

-- 25/26 ≈ 0.962 > 0.9 이므로 스팸으로 (거부/통과)?
```

<details>
<summary>💡 답 보기</summary>

```lean
example : spamScore (1/8) (1/200) = 25/26 := by
  unfold spamScore; norm_num

-- 25/26 ≈ 0.962 > 0.9 → 스팸으로 거부해야 한다!
```

</details>

---

## 📝 연습문제 — sorry로 직접 증명하기

### 연습 8: 축구 선수 스테로이드 (Rosen 연습문제 6)

> 모든 축구 선수의 5%가 스테로이드를 복용. 복용자의 98%가 양성, 비복용자의 12%가 양성. 양성인 선수가 실제 복용했을 확률은?

```lean
example : bayes (98/100) (5/100) (12/100) (95/100) = 49/163 := by
  sorry
```

<details>
<summary>💡 답 보기</summary>

```lean
example : bayes (98/100) (5/100) (12/100) (95/100) = 49/163 := by
  unfold bayes; norm_num
```

**해설**: 분자 = (98/100)·(5/100) = 490/10000. 분모 = 490/10000 + (12/100)·(95/100) = 490/10000 + 1140/10000 = 1630/10000. 결과 = 490/1630 = 49/163 ≈ 0.3006 ≈ 약 30%.

</details>

### 연습 9: HIV 검사 (Rosen 연습문제 9)

> 임상에서 환자의 8%가 HIV에 감염. 혈액검사에서 감염된 환자의 98%가 양성, 감염되지 않은 환자의 3%가 양성.
> (a) 양성인 환자가 HIV에 감염되었을 확률

```lean
-- (a) p(감염|양성)
example : bayes (98/100) (8/100) (3/100) (92/100) = 196/265 := by
  sorry
```

<details>
<summary>💡 답 보기</summary>

```lean
example : bayes (98/100) (8/100) (3/100) (92/100) = 196/265 := by
  unfold bayes; norm_num

-- 196/265 ≈ 0.7396 ≈ 약 74%
```

</details>

### 연습 10: 교통수단 추정 (Rosen 연습문제 16)

> 출근 교통수단: 자전거(지각 확률 5%), 자가용(지각 확률 타면 전용차선 덕에 20%), 버스(지각 확률 교통체증 50%). 지각한 직원이 자가용으로 출근했을 확률은? (각 교통수단 선택 확률 모두 1/3)

```lean
-- 일반화 베이즈: 3개 원인
-- F₀ = 자전거, F₁ = 자가용, F₂ = 버스
-- p(지각|자전거) = 5/100, p(지각|자가용) = 20/100, p(지각|버스) = 50/100
-- 각 p(Fᵢ) = 1/3
-- 구하는 것: p(자가용 | 지각) = p(F₁ | E)

-- 직접 계산 방식
example :
    (20/100 : ℚ) * (1/3) / ((5/100) * (1/3) + (20/100) * (1/3) + (50/100) * (1/3))
    = 4/15 := by
  sorry
```

<details>
<summary>💡 답 보기</summary>

```lean
example :
    (20/100 : ℚ) * (1/3) / ((5/100) * (1/3) + (20/100) * (1/3) + (50/100) * (1/3))
    = 4/15 := by
  norm_num

-- 4/15 ≈ 0.267 ≈ 약 26.7%
```

</details>

### 연습 11: 다중 단어 스팸 필터 (Rosen 예제 4)

> "stock" 단어: 스팸 2000개 중 400개, 비스팸 1000개 중 60개.
> "undervalued" 단어: 스팸 2000개 중 200개, 비스팸 1000개 중 25개.
> 두 단어가 모두 사용되었을 때 스팸일 확률 추정. 스팸 기준 0.9이면 거부하는가?

```lean
-- p(stock) = 400/2000 = 1/5, q(stock) = 60/1000 = 3/50
-- p(undervalued) = 200/2000 = 1/10, q(undervalued) = 25/1000 = 1/40

-- r(stock, undervalued) = p(stock)·p(undervalued) / (p(stock)·p(undervalued) + q(stock)·q(undervalued))

example :
    ((1/5 : ℚ) * (1/10)) / ((1/5) * (1/10) + (3/50) * (1/40))
    = 40/43 := by
  sorry
```

<details>
<summary>💡 답 보기</summary>

```lean
example :
    ((1/5 : ℚ) * (1/10)) / ((1/5) * (1/10) + (3/50) * (1/40))
    = 40/43 := by
  norm_num

-- 40/43 ≈ 0.930 > 0.9 → 스팸으로 거부!
```

</details>

### 연습 12: 조류 독감 검사 (Rosen 연습문제 10)

> 환자의 4%가 조류 독감에 감염. 감염된 환자의 97%가 양성, 감염되지 않은 환자의 2%가 양성.
> (a) 양성이면서 실제 조류 독감에 감염되었을 확률
> (b) 양성이면서 조류 독감에 감염되지 않았을 확률

```lean
-- (a) p(감염 | 양성)
example : bayes (97/100) (4/100) (2/100) (96/100) = 97/145 := by
  sorry

-- (b) 이 문제는 1 - p(감염 | 양성) 이다
example : 1 - (97 : ℚ)/145 = 48/145 := by
  sorry
```

<details>
<summary>💡 답 보기</summary>

```lean
-- (a)
example : bayes (97/100) (4/100) (2/100) (96/100) = 97/145 := by
  unfold bayes; norm_num

-- 97/145 ≈ 0.669 ≈ 약 66.9%

-- (b)
example : 1 - (97 : ℚ)/145 = 48/145 := by
  norm_num

-- 48/145 ≈ 0.331 ≈ 약 33.1%
```

</details>

### 연습 13: 여사건 확률의 보조정리

> `0 ≤ p`이고 `p ≤ 1`일 때, `1 - p`도 0과 1 사이임을 증명하라.

```lean
lemma complement_in_range (p : ℚ) (h0 : 0 ≤ p) (h1 : p ≤ 1) :
    0 ≤ 1 - p ∧ 1 - p ≤ 1 := by
  sorry
```

<details>
<summary>💡 답 보기</summary>

```lean
lemma complement_in_range (p : ℚ) (h0 : 0 ≤ p) (h1 : p ≤ 1) :
    0 ≤ 1 - p ∧ 1 - p ≤ 1 := by
  constructor <;> linarith
```

**해설**: `constructor`로 `∧`(그리고)를 두 목표로 나누고, `<;>`로 두 목표 모두에 `linarith`를 적용한다. `linarith`는 선형 산술 부등식을 자동으로 해결한다.

</details>

### 연습 14: 베이즈 분모가 양수

> `0 < a`, `0 < b`, `0 < c`, `0 < d`일 때 `0 < a * b + c * d`를 증명하라.

```lean
example (a b c d : ℚ) (ha : 0 < a) (hb : 0 < b) (hc : 0 < c) (hd : 0 < d) :
    0 < a * b + c * d := by
  sorry
```

<details>
<summary>💡 답 보기</summary>

```lean
example (a b c d : ℚ) (ha : 0 < a) (hb : 0 < b) (hc : 0 < c) (hd : 0 < d) :
    0 < a * b + c * d := by
  positivity
```

**해설**: `positivity`는 양수/비음수 목표를 자동으로 해결한다. 수동으로 하려면 `have h1 := mul_pos ha hb; have h2 := mul_pos hc hd; linarith`도 가능하다.

</details>

---

## 🎯 이 파트의 요약

| 개념 | 공식 / 설명 |
|---|---|
| **베이즈 정리**(Bayes' theorem) | p(F\|E) = p(E\|F)·p(F) / [p(E\|F)·p(F) + p(E\|F̄)·p(F̄)] |
| **일반화된 베이즈 정리** | p(Fⱼ\|E) = p(E\|Fⱼ)·p(Fⱼ) / Σᵢ p(E\|Fᵢ)·p(Fᵢ) |
| **참 양성**(true positive) | 실제 양성이 양성 판정 |
| **거짓 양성**(false positive) | 실제 음성인데 양성 판정 |
| **베이지안 스팸 필터** | r(w) = p(w) / (p(w) + q(w)) |
| Lean 전술 `positivity` | 양수/비음수 자동 증명 |
| Lean 전술 `calc` | 단계별 등식/부등식 증명 |

> 🚀 다음 Part 10-D에서는 **기댓값**(expected value)과 **분산**(variance)을 배운다. 확률변수의 "평균"과 "퍼짐 정도"를 수학적으로 정의하고 Lean 4로 형식화하자!
