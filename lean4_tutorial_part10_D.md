# 📘 Lean 4 튜토리얼 — Part 10-D: 기댓값

> **Rosen 이산수학 8판 §7.4 기반 · Mathematics in Lean 참조**
> Part 10-C에서 **베이즈 정리**를 배웠다. 이제 확률변수의 "평균"에 해당하는 **기댓값**(expected value)을 배운다.

---

## 🎯 이 파트에서 배울 것

1. **확률변수**(random variable)의 **기댓값**(expected value) 정의
2. 주사위, 동전 등의 기댓값 계산
3. **베르누이 시행**(Bernoulli trial)의 기댓값
4. **기댓값의 선형성**(linearity of expectation) — 놀랍도록 강력한 성질
5. **기하 분포**(geometric distribution)의 기댓값
6. **독립 확률변수**(independent random variables)
7. Lean 4의 `Finset.sum`을 활용한 형식화

---

## 10D.0 왜 기댓값이 필요한가?

### 🤔 동기 부여

동전을 100번 던진다. 앞면이 몇 번 나올 것으로 **예측**할 수 있을까? 직관적으로 약 50번이라고 답할 것이다. 이 "50"이 바로 **기댓값**이다!

기댓값은 다음과 같은 질문에 답할 수 있다:
- 주사위를 던져서 나오는 숫자의 **평균**은?
- 복권의 **예상 상금**은?
- 알고리즘의 **평균 실행 시간**은?
- 도박에서 **누가 유리한지** 어떻게 판단할까?

---

## 10D.1 기댓값의 정의

### 📐 정의 1

> **표본공간**(sample space) `S`에서의 **확률변수**(random variable) `X`의 **기댓값**(expected value), 혹은 **평균**(mean)은 다음과 같이 정의된다:
>
> ```
> E(X) = Σ p(s) · X(s)
>        s∈S
> ```
>
> 즉, 표본공간의 모든 원소에 대해서 원소의 확률과 그 원소의 확률변수 값의 **곱**을 모두 더한 것이다.

### 🧠 직관적 이해

기댓값은 **가중 평균**(weighted average)이다. 각 결과에 그 결과가 일어날 확률을 **가중치**로 곱해서 더한다.

| 개념 | 일반 평균 | 기댓값 (가중 평균) |
|---|---|---|
| 계산 방식 | 모든 값을 더하고 개수로 나눔 | 각 값 × 확률을 더함 |
| 가중치 | 모두 동일 | 확률에 따라 다름 |
| 예시 | (1+2+3)/3 = 2 | 1·(1/6)+2·(1/6)+...+6·(1/6) = 7/2 |

### Lean 4에서의 기댓값

```lean
import Mathlib.Data.Rat.Basic
import Mathlib.Data.Finset.Basic
import Mathlib.Tactic

open Finset

/-- 유한 표본공간에서 확률변수 X의 기댓값
    S = Fin n (0, 1, ..., n-1), p = 확률함수, X = 확률변수 -/
def expectedValue (n : ℕ) (p : Fin n → ℚ) (X : Fin n → ℚ) : ℚ :=
  ∑ s : Fin n, p s * X s
```

> 💡 `∑ s : Fin n, p s * X s`는 Lean 4에서 유한 합을 나타낸다. `Fin n`은 `{0, 1, ..., n-1}` 집합의 타입이고, `Finset.sum`이 자동으로 사용된다. Part 5-C에서 배운 `Σ` 표기법의 활용이다!

---

## 10D.2 예제 1: 주사위의 기댓값

### 📋 문제

공평한 주사위를 던져서 나오는 숫자를 확률변수 `X`라 하자. `X`의 기댓값은 얼마인가?

### 풀이

`X`는 1, 2, 3, 4, 5, 6을 각각 1/6의 확률로 취한다:

```
E(X) = 1/6 · 1 + 1/6 · 2 + 1/6 · 3 + 1/6 · 4 + 1/6 · 5 + 1/6 · 6
     = 1/6 · (1 + 2 + 3 + 4 + 5 + 6)
     = 1/6 · 21
     = 7/2 = 3.5
```

### Lean 4로 확인

```lean
-- 방법 1: 직접 계산
example : (1/6 : ℚ) * 1 + (1/6) * 2 + (1/6) * 3 + (1/6) * 4 + (1/6) * 5 + (1/6) * 6
    = 7/2 := by
  norm_num

-- 방법 2: expectedValue 함수 사용
-- 주사위: 6개 결과, 각 확률 1/6, 값 1~6
#eval expectedValue 6 (fun _ => 1/6) (fun i => (i.val + 1 : ℚ))
-- 결과: 7/2
```

> 💡 주사위의 기댓값 7/2 = 3.5는 실제로 나올 수 없는 값이다! 기댓값은 "한 번 던져서 나올 값의 예측"이 아니라, "매우 많이 던졌을 때 평균적으로 수렴하는 값"이다.

---

## 10D.3 예제 2: 동전 세 번 던지기

### 📋 문제

동전을 세 번 던져서 가능한 8가지의 결과를 표본공간 `S`라 하고, 각 결과에 앞면의 수를 할당하는 확률변수를 `X`라 하자. `X`의 기댓값은 얼마인가?

### 풀이

| 결과 | X(결과) | 확률 |
|---|---|---|
| HHH | 3 | 1/8 |
| HHT | 2 | 1/8 |
| HTH | 2 | 1/8 |
| THH | 2 | 1/8 |
| HTT | 1 | 1/8 |
| THT | 1 | 1/8 |
| TTH | 1 | 1/8 |
| TTT | 0 | 1/8 |

```
E(X) = 1/8 · (3 + 2 + 2 + 2 + 1 + 1 + 1 + 0)
     = 1/8 · 12
     = 3/2
```

```lean
example : (1/8 : ℚ) * (3 + 2 + 2 + 2 + 1 + 1 + 1 + 0) = 3/2 := by
  norm_num
```

> 💡 동전을 세 번 던졌을 때 앞면이 나오는 수의 기댓값은 3/2 = 1.5이다. 이것은 "동전 1번 × 앞면 확률 1/2 × 3번 = 3/2"로도 직관적으로 이해할 수 있다. 이 직관은 바로 다음에 배울 **기댓값의 선형성**에서 정확히 설명된다!

---

## 10D.4 정리 1: 기댓값의 다른 표현

만약 확률변수 `X`의 **치역**(가능한 값의 집합)이 제한적이라면, 같은 값을 주는 결과들을 묶어서 계산할 수 있다.

### 📐 정리 1

> `X`가 확률변수이고 `p(X = r)`이 `X = r`일 확률이어서 `Σ_{s∈S, X(s)=r} p(s)`로 표현되면, 기댓값은 다음과 같이 계산할 수 있다:
>
> ```
> E(X) = Σ p(X = r) · r
>        r∈X(S)
> ```

이것은 단순히 "같은 X값을 가진 결과들을 하나로 묶는다"는 뜻이다.

### 예제 3: 주사위 두 개 합의 기댓값

```
X = 두 주사위의 합. X(S) = {2, 3, 4, ..., 12}
p(X = 2) = 1/36, p(X = 3) = 2/36, ..., p(X = 7) = 6/36, ..., p(X = 12) = 1/36

E(X) = 2·(1/36) + 3·(2/36) + 4·(3/36) + 5·(4/36) + 6·(5/36) + 7·(6/36)
     + 8·(5/36) + 9·(4/36) + 10·(3/36) + 11·(2/36) + 12·(1/36)
     = 7
```

```lean
-- 직접 계산
example :
    2*(1/36 : ℚ) + 3*(2/36) + 4*(3/36) + 5*(4/36) + 6*(5/36) + 7*(6/36)
  + 8*(5/36) + 9*(4/36) + 10*(3/36) + 11*(2/36) + 12*(1/36) = 7 := by
  norm_num
```

> 💡 **주사위 두 개 합의 기댓값 = 7**이다. 이것은 "주사위 하나의 기댓값 7/2 + 주사위 하나의 기댓값 7/2 = 7"로도 얻어진다. 이것이 기댓값의 선형성이다!

---

## 10D.5 정리 2: 베르누이 시행의 기댓값

### 📐 정리 2

> 한 번 시행에서 성공의 확률이 `p`인 서로 독립인 **베르누이 시행**(Bernoulli trial)을 `n`번 계속할 경우 **성공 횟수의 기댓값**은 `np`이다.

### 증명 아이디어

`X`를 `n`번 시행에서 성공 횟수라 하면, §7.2에서 배운 이항분포에 의해:

```
p(X = k) = C(n, k) · p^k · q^(n-k)     (q = 1 - p)
```

직접 계산하면:

```
E(X) = Σ_{k=0}^{n} k · C(n,k) · p^k · q^(n-k)
     = np
```

이 계산은 `kC(n,k) = nC(n-1,k-1)` 항등식과 이항정리를 사용한다.

```lean
-- n=10, p=1/2 일 때 기댓값 = 10 · 1/2 = 5
example : (10 : ℚ) * (1/2) = 5 := by norm_num

-- n=100, p=1/6 일 때 기댓값 = 100/6 = 50/3
example : (100 : ℚ) * (1/6) = 50/3 := by norm_num
```

> 💡 베르누이 시행에서 기댓값 공식 `E(X) = np`는 직관과 완벽하게 일치한다. 성공 확률이 `p`인 시행을 `n`번 하면, 평균적으로 `np`번 성공한다.

---

## 10D.6 정리 3: 기댓값의 선형성 ⭐

이것은 확률론에서 가장 유용한 정리 중 하나이다!

### 📐 정리 3 (기댓값의 선형성)

> 양의 정수 `n`에 대해서 `Xᵢ` (i = 1, 2, ..., n)가 `S`에서 정의된 확률변수이고 `a`와 `b`가 실수이면:
>
> **(i)** `E(X₁ + X₂ + ... + Xₙ) = E(X₁) + E(X₂) + ... + E(Xₙ)`
>
> **(ii)** `E(aX + b) = aE(X) + b`

### 🧠 왜 놀라운가?

**(i)**의 놀라운 점: **독립이 아니어도 성립한다!** 보통 확률에서 "독립"이라는 조건이 필요한 경우가 많은데, 기댓값의 선형성은 **무조건** 성립한다.

### 증명 아이디어 ((i)의 n=2 경우)

```
E(X₁ + X₂) = Σ p(s) · (X₁(s) + X₂(s))
            = Σ p(s) · X₁(s) + Σ p(s) · X₂(s)    (합의 분배)
            = E(X₁) + E(X₂)
```

### Lean 4로 표현

```lean
-- 기댓값의 선형성 (n=2 경우)
-- Finset.sum의 덧셈 분배 법칙을 사용한다
theorem expected_value_add (n : ℕ) (p X₁ X₂ : Fin n → ℚ) :
    (∑ s : Fin n, p s * (X₁ s + X₂ s))
    = (∑ s : Fin n, p s * X₁ s) + (∑ s : Fin n, p s * X₂ s) := by
  simp [mul_add, Finset.sum_add_distrib]
```

> 💡 `simp [mul_add, Finset.sum_add_distrib]`가 핵심이다:
> - `mul_add`: `a * (b + c) = a * b + a * c` (분배법칙)
> - `Finset.sum_add_distrib`: `Σ(f(s) + g(s)) = Σf(s) + Σg(s)` (합의 분배)

### 예제 4: 선형성으로 주사위 합 다시 계산

```lean
-- 주사위 두 개의 합의 기댓값
-- X₁ = 첫 번째 주사위, X₂ = 두 번째 주사위
-- E(X₁ + X₂) = E(X₁) + E(X₂) = 7/2 + 7/2 = 7 ✓

example : (7/2 : ℚ) + 7/2 = 7 := by norm_num
```

### 예제 5: 베르누이의 기댓값을 선형성으로

```lean
-- 각 시행 Xᵢ: 성공이면 1, 실패이면 0
-- E(Xᵢ) = 1·p + 0·(1-p) = p
-- X = X₁ + X₂ + ... + Xₙ (성공 횟수)
-- E(X) = E(X₁) + ... + E(Xₙ) = np  ✓

-- n = 10, p = 1/3 일 때
example : 10 * (1/3 : ℚ) = 10/3 := by norm_num
```

---

## 10D.7 예제 6: 모자 관리 문제 (재미있는 문제!)

### 📋 문제

음식점의 점원이 `n`명의 손님의 모자에 번호표를 붙이는 것을 잊고 모자를 보관하였다. 손님이 모자를 찾으러 왔을 때는 남아 있는 모자 중에서 아무것이나 꺼내서 돌려준다. 맞는 모자를 돌려주는 횟수의 기댓값은 얼마인가?

### 풀이 (기댓값의 선형성 활용!)

`Xᵢ`를 `i`번째 사람이 맞는 모자를 받으면 1, 아니면 0으로 정의한다.

그러면 `X = X₁ + X₂ + ... + Xₙ`이 맞는 모자를 받은 총 수이다.

핵심: 각 `Xᵢ`의 기댓값은?

`i`번째 사람이 맞는 모자를 받을 확률은 `1/n`이다 (어떤 사람에게 모자를 돌려주는 사건의 가능성은 모든 모자에 대해서 동일하므로).

```
E(Xᵢ) = 1 · (1/n) + 0 · (1 - 1/n) = 1/n
```

기댓값의 선형성에 의해:

```
E(X) = E(X₁) + E(X₂) + ... + E(Xₙ) = n · (1/n) = 1
```

```lean
-- n명의 손님에 대해 맞는 모자를 받는 수의 기댓값은 항상 1!
-- n = 10
example : 10 * (1/10 : ℚ) = 1 := by norm_num
-- n = 100
example : 100 * (1/100 : ℚ) = 1 := by norm_num
-- n = 1000000
example : 1000000 * (1/1000000 : ℚ) = 1 := by norm_num
```

> 😲 놀라운 결과! 손님이 10명이든 100만 명이든, 맞는 모자를 받는 사람 수의 기댓값은 **항상 정확히 1명**이다!

---

## 10D.8 예제 7: 순열에서 반전 개수의 기댓값

### 📋 문제

양의 정수 `n`에 대해서 임의의 순열을 생각할 때 순열에서의 **반전**(inversion) 개수의 기댓값을 찾아라.

**반전**이란: `i < j`이면서 `j`가 `i`보다 앞에 나오는 순서 쌍 `(i, j)`를 말한다.

예를 들어 순열 `3, 5, 1, 4, 2`에서의 반전은 `(1,3), (1,5), (2,3), (2,4), (2,5), (4,5)` 으로 6개이다.

### 풀이

`Iᵢⱼ`를 `(i,j)`가 반전이면 1, 아니면 0으로 정의한다.

임의의 순열에서 `i`가 `j`보다 앞에 나오는 것과 뒤에 나오는 것은 **동일한 확률** 1/2로 발생한다.

따라서 `E(Iᵢⱼ) = 1/2`.

`X = Σ_{1≤i<j≤n} Iᵢⱼ`이므로 기댓값의 선형성에 의해:

```
E(X) = Σ_{1≤i<j≤n} E(Iᵢⱼ) = C(n,2) · (1/2) = n(n-1)/4
```

```lean
-- n = 5일 때 반전 개수의 기댓값
-- C(5,2) · 1/2 = 10 · 1/2 = 5
example : (5 : ℚ) * 4 / 4 = 5 := by norm_num

-- n = 10일 때
example : (10 : ℚ) * 9 / 4 = 45/2 := by norm_num
```

---

## 10D.9 기하 분포와 기댓값

### 📐 정의 2 (기하 분포)

> `p`가 `0 ≤ p ≤ 1`인 실수일 때 `k = 1, 2, 3, ...`에 대해 `p(X = k) = (1 - p)^(k-1) · p`이면 확률변수 `X`는 `p`를 **매개변수**(parameter)로 하는 **기하 분포**(geometric distribution)를 갖는다고 한다.

### 🧠 직관

동전의 뒷면이 나올 때까지 계속 던진다. 뒷면이 나올 때까지 던진 횟수가 기하 분포를 따른다.

### 📐 정리 4

> 확률변수가 `p`를 매개변수로 하는 기하 분포를 `X`라 하면 `E(X) = 1/p`이다.

```lean
-- 동전이 평평하면 p = 1/2이므로, 뒷면이 나올 때까지 기댓값 = 1/(1/2) = 2
example : 1 / (1/2 : ℚ) = 2 := by norm_num

-- 주사위에서 6이 나올 때까지 기댓값 = 1/(1/6) = 6
example : 1 / (1/6 : ℚ) = 6 := by norm_num
```

> 💡 평평한 동전을 뒷면이 나올 때까지 던지면, 평균 2번이면 뒷면이 나온다!

---

## 10D.10 독립 확률변수

### 📐 정의 3

> **표본공간**(sample space)에서 정의된 확률변수 `X`와 `Y`가 다음 조건을 만족하면 **독립**(independent)이라고 한다:
>
> ```
> p(X = r₁ 이고 Y = r₂) = p(X = r₁) · p(Y = r₂)
> ```
>
> 모든 실수 `r₁`과 `r₂`에 대해서.

### 📐 정리 5 (독립 확률변수의 곱의 기댓값)

> `S`에서 정의된 `X`와 `Y`가 **독립인 확률변수**이면 `E(XY) = E(X)·E(Y)`이다.

⚠️ 주의: **독립이 아니면** `E(XY) ≠ E(X)E(Y)`일 수 있다!

```lean
-- 독립인 경우: 두 주사위
-- E(X₁) = 7/2, E(X₂) = 7/2
-- E(X₁ · X₂) = E(X₁) · E(X₂) = 49/4

example : (7/2 : ℚ) * (7/2) = 49/4 := by norm_num
```

### 예제 13: 독립이 아닌 경우 (반례)

```lean
-- 동전 두 개: X = 앞면 수, Y = 뒷면 수
-- p(X=2) = 1/4, p(X=1) = 1/2, p(X=0) = 1/4
-- E(X) = 1, E(Y) = 1
-- XY: 앞면만/뒷면만 → XY=0, 앞뒤 하나씩 → XY=1
-- E(XY) = 0·(1/4) + 1·(1/2) + 0·(1/4) = 1/2
-- E(X)·E(Y) = 1·1 = 1
-- E(XY) ≠ E(X)E(Y) → X와 Y는 독립이 아니다!

example : (1/2 : ℚ) ≠ 1 := by norm_num
```

---

## 10D.11 평균 계산 복잡도

기댓값은 알고리즘의 **평균 계산 복잡도**(average-case complexity)를 구하는 데 사용된다.

### 예제 8: 선형 탐색의 평균 복잡도

```
x가 리스트에 있을 확률이 p, 리스트의 n개 원소 중 어떤 위치에 있을 가능성은 동일.
x가 리스트에 없으면 2n+2번의 비교 연산이 필요.

E = p(n+2) + (2n+2)q    (q = 1-p)
```

```lean
-- p = 1일 때 (반드시 있음): E = n+2
-- p = 1/2일 때: E = (n+2)/2 + (2n+2)/2 = (3n+4)/2
-- p = 0일 때 (반드시 없음): E = 2n+2

-- n = 100, p = 1/2
example : (1/2 : ℚ) * (100 + 2) + (2*100 + 2) * (1/2) = 152 := by norm_num
```

### 예제 9: 삽입 정렬의 평균 복잡도

삽입 정렬에서 비교 연산의 평균 횟수는:

```
E(X) = (n² + 3n - 4) / 4
```

```lean
-- n = 10일 때: (100 + 30 - 4)/4 = 126/4 = 63/2
example : ((10 : ℚ)^2 + 3*10 - 4) / 4 = 63/2 := by norm_num

-- n = 100일 때: (10000 + 300 - 4)/4 = 10296/4 = 2574
example : ((100 : ℚ)^2 + 3*100 - 4) / 4 = 2574 := by norm_num
```

---

## 📝 연습문제 — 설명형 예제

### 연습 1: 동전 5번 앞면 횟수의 기댓값

> 동전을 5번 던져 앞면이 나온 횟수의 기댓값은 얼마인가? (Rosen §7.4 연습문제 1)

**풀이**: 베르누이 시행, `n = 5`, `p = 1/2`. `E(X) = np = 5 · 1/2 = 5/2`

```lean
example : 5 * (1/2 : ℚ) = 5/2 := by norm_num
```

### 연습 2: 동전 10번 앞면 횟수의 기댓값

> 동전을 10번 던져 앞면이 나온 횟수의 기댓값은? (Rosen §7.4 연습문제 2)

```lean
example : 10 * (1/2 : ℚ) = 5 := by norm_num
```

### 연습 3: 주사위 10번 합의 기댓값

> 주사위를 10번 던져 나온 숫자의 합의 기댓값은? (Rosen §7.4 연습문제 3)

```lean
-- 주사위 하나의 기댓값 7/2, 선형성에 의해 10배
example : 10 * (7/2 : ℚ) = 35 := by norm_num
```

---

## 📝 연습문제 — 괄호 채우기 (skeleton)

### 연습 4: 편향 동전 기댓값

> 앞면이 나올 확률이 0.6인 동전을 10번 던져 앞면이 나온 횟수의 기댓값은? (Rosen 연습문제 4)

```lean
example : 10 * (⟨여기를 채우세요⟩ : ℚ) = 6 := by
  norm_num
```

<details>
<summary>💡 답 보기</summary>

```lean
example : 10 * (3/5 : ℚ) = 6 := by
  norm_num
```

**해설**: `p = 0.6 = 3/5`. `E(X) = np = 10 · 3/5 = 6`.

</details>

### 연습 5: 특별한 주사위

> 숫자 3이 나올 확률이 다른 숫자에 비해서 3배 많은 특별한 주사위를 두 개를 던졌을 때 두 눈의 합의 기댓값은 얼마인가? (Rosen 연습문제 5)

**힌트**: 3이 나올 확률 = 3/8, 나머지(1,2,4,5,6)가 나올 확률 = 각 1/8

```lean
-- 하나의 특별한 주사위 기댓값:
-- E = 1·(1/8) + 2·(1/8) + 3·(3/8) + 4·(1/8) + 5·(1/8) + 6·(1/8)

example :
    1*(1/8 : ℚ) + 2*(1/8) + 3*(3/8) + 4*(1/8) + 5*(1/8) + 6*(1/8)
    = (⟨여기를 채우세요⟩) := by
  norm_num

-- 두 주사위 합의 기댓값 = 2 × (한 주사위 기댓값)
```

<details>
<summary>💡 답 보기</summary>

```lean
-- 한 주사위 기댓값
example :
    1*(1/8 : ℚ) + 2*(1/8) + 3*(3/8) + 4*(1/8) + 5*(1/8) + 6*(1/8)
    = 27/8 := by
  norm_num

-- 두 주사위 합 기댓값 = 27/8 + 27/8 = 27/4
example : 2 * (27/8 : ℚ) = 27/4 := by
  norm_num
```

</details>

### 연습 6: 복권 기댓값

> 1, 2, 3, ..., 50에서 뽑은 6개 숫자를 모두 맞추면 1,000만 달러를 받고, 그렇지 않으면 아무것도 받지 못하는 1달러짜리 복권을 샀을 때의 기댓값은 얼마인가? (Rosen 연습문제 6)

```lean
-- C(50,6) = 15890700
-- 당첨 확률 = 1/15890700
-- 기댓값 = 10000000/15890700 - 1 (복권 비용 1달러를 뺌)
-- = 10000000/15890700 - 1

-- 먼저 순수 상금 기댓값
example : (10000000 : ℚ) / 15890700 = (⟨여기를 채우세요⟩) := by
  norm_num
```

<details>
<summary>💡 답 보기</summary>

```lean
-- 순수 상금 기댓값
example : (10000000 : ℚ) / 15890700 = 1000000/1589070 := by
  norm_num

-- 약 0.629달러. 복권 가격 1달러를 빼면 기댓값은 약 -0.371달러.
-- 즉, 복권을 살 때마다 평균 약 37센트를 잃는다!
```

</details>

### 연습 7: 기댓값의 선형성 활용

> 3개의 주사위를 던졌을 때 나온 세 눈의 합의 기댓값은 얼마인가? (Rosen 연습문제 8)

```lean
example : 3 * (7/2 : ℚ) = (⟨여기를 채우세요⟩) := by
  norm_num
```

<details>
<summary>💡 답 보기</summary>

```lean
example : 3 * (7/2 : ℚ) = 21/2 := by
  norm_num
```

</details>

### 연습 8: 기하 분포 기댓값

> 주사위를 던져 6이 나올 때까지의 기댓값은? (p = 1/6)

```lean
example : 1 / (1/6 : ℚ) = (⟨여기를 채우세요⟩) := by
  norm_num
```

<details>
<summary>💡 답 보기</summary>

```lean
example : 1 / (1/6 : ℚ) = 6 := by
  norm_num
```

</details>

---

## 📝 연습문제 — sorry로 직접 증명하기

### 연습 9: 기댓값의 선형성 (ii) 증명

> `E(aX + b) = aE(X) + b`를 증명하라. (`Σ_{s∈S} p(s) = 1` 사실을 이용)

```lean
theorem expected_linear (n : ℕ) (p X : Fin n → ℚ) (a b : ℚ)
    (hprob : ∑ s : Fin n, p s = 1) :
    (∑ s : Fin n, p s * (a * X s + b))
    = a * (∑ s : Fin n, p s * X s) + b := by
  sorry
```

<details>
<summary>💡 답 보기</summary>

```lean
theorem expected_linear (n : ℕ) (p X : Fin n → ℚ) (a b : ℚ)
    (hprob : ∑ s : Fin n, p s = 1) :
    (∑ s : Fin n, p s * (a * X s + b))
    = a * (∑ s : Fin n, p s * X s) + b := by
  simp [mul_add, mul_comm, mul_left_comm, Finset.sum_add_distrib, ← Finset.mul_sum]
  linarith [hprob]
```

**해설**: `p(s)·(aX(s) + b) = a·p(s)·X(s) + b·p(s)`로 분배한 후, `Σb·p(s) = b·Σp(s) = b·1 = b`를 이용한다.

</details>

### 연습 10: 삽입 정렬 복잡도 계산

> `n = 20`일 때 삽입 정렬의 평균 비교 연산 횟수 `(n² + 3n - 4)/4`를 계산하라.

```lean
example : ((20 : ℚ)^2 + 3*20 - 4) / 4 = 114 := by
  sorry
```

<details>
<summary>💡 답 보기</summary>

```lean
example : ((20 : ℚ)^2 + 3*20 - 4) / 4 = 114 := by
  norm_num
```

</details>

### 연습 11: 기하 분포의 확률 합 확인

> 기하 분포에서 `p = 1/2`일 때, 처음 4개 항의 확률 합을 구하라: `Σ_{k=1}^{4} (1/2)^k`

```lean
example : (1/2 : ℚ) + (1/2)^2 + (1/2)^3 + (1/2)^4 = 15/16 := by
  sorry
```

<details>
<summary>💡 답 보기</summary>

```lean
example : (1/2 : ℚ) + (1/2)^2 + (1/2)^3 + (1/2)^4 = 15/16 := by
  norm_num
```

**해설**: 1/2 + 1/4 + 1/8 + 1/16 = 8/16 + 4/16 + 2/16 + 1/16 = 15/16. 무한히 더하면 1에 수렴한다.

</details>

### 연습 12: 반전 개수의 기댓값

> `n = 8`일 때 임의 순열에서의 반전 개수의 기댓값 `n(n-1)/4`를 계산하라.

```lean
example : (8 : ℚ) * 7 / 4 = 14 := by
  sorry
```

<details>
<summary>💡 답 보기</summary>

```lean
example : (8 : ℚ) * 7 / 4 = 14 := by
  norm_num
```

</details>

### 연습 13: 기댓값의 합 분해

> 두 확률변수의 합의 기댓값이 각 기댓값의 합과 같음을 `Finset.sum_add_distrib`를 사용하여 증명하라.

```lean
-- 힌트: Finset.sum_add_distrib를 사용하라
example (n : ℕ) (f g : Fin n → ℚ) :
    (∑ i : Fin n, (f i + g i)) = (∑ i : Fin n, f i) + (∑ i : Fin n, g i) := by
  sorry
```

<details>
<summary>💡 답 보기</summary>

```lean
example (n : ℕ) (f g : Fin n → ℚ) :
    (∑ i : Fin n, (f i + g i)) = (∑ i : Fin n, f i) + (∑ i : Fin n, g i) := by
  exact Finset.sum_add_distrib
```

</details>

### 연습 14: 상수 곱의 분배

> `Σ (a · f(i)) = a · Σ f(i)` 를 증명하라.

```lean
example (n : ℕ) (a : ℚ) (f : Fin n → ℚ) :
    (∑ i : Fin n, a * f i) = a * (∑ i : Fin n, f i) := by
  sorry
```

<details>
<summary>💡 답 보기</summary>

```lean
example (n : ℕ) (a : ℚ) (f : Fin n → ℚ) :
    (∑ i : Fin n, a * f i) = a * (∑ i : Fin n, f i) := by
  rw [← Finset.mul_sum]
```

**해설**: `Finset.mul_sum`은 `a * Σf = Σ(a*f)`를 말한다. 방향을 바꿔야 하므로 `←`를 사용한다.

</details>

---

## 🎯 이 파트의 요약

| 개념 | 공식 / 설명 |
|---|---|
| **기댓값**(expected value) | E(X) = Σ p(s)·X(s) |
| **베르누이 기댓값** | E(X) = np |
| **기댓값의 선형성** | E(X₁+...+Xₙ) = E(X₁)+...+E(Xₙ), E(aX+b) = aE(X)+b |
| **기하 분포 기댓값** | E(X) = 1/p |
| **독립 확률변수 곱** | E(XY) = E(X)·E(Y) (독립일 때만!) |
| Lean `Finset.sum_add_distrib` | Σ(f+g) = Σf + Σg |
| Lean `Finset.mul_sum` | a·Σf = Σ(a·f) |

> 🚀 다음 Part 10-E에서는 **분산**(variance)과 **체비쇼프 부등식**(Chebyshev's inequality)을 배운다!
